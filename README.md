# Toxic Language Detection in Online Chats ğŸ§ ğŸ’¬

Detecting toxic and non-toxic messages using classical and transformer-based NLP models.

---

## ğŸ”— Run in Google Colab  
Click below to run the full project in your browser (no installation needed):

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ZAjqivhGJRA4Go_x1mpitkPvCJxMnPHV?usp=sharing)

---

## ğŸ—‚ï¸ Project Structure
- `main.py` â€” Full pipeline for training and evaluation.
- `data/train.csv` â€” Toxic comment dataset (from Kaggle).
- `requirements.txt` â€” Required libraries.
- `notebooks/` â€” Optional Jupyter or Colab notebooks.
- `graphical_abstract/` â€” Project overview image.
- `presentations/` â€” Slides for proposal, progress, final.

---

## ğŸ§ª Models Used
| Model              | Description |
|-------------------|-------------|
| Naive Bayes        | Baseline using TF-IDF |
| Logistic Regression| Stronger classical ML model |
| DistilBERT         | Transformer fine-tuned on small dataset |

---

## ğŸ“Š Evaluation Metrics
- Accuracy  
- Precision  
- Recall  
- F1 Score  
- Confusion Matrix

---

## ğŸ“ Dataset
Source: [Jigsaw Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)

---

## âœï¸ Authors
- [Your Name(s) Here]

---

## ğŸ“Œ Notes
- For local execution: install requirements and place `train.csv` in the `/data/` folder.
- For best results, use a GPU when running DistilBERT.

---
